{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read Mask Rcnn model\n",
    "2. Read image in folder\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import time\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from object_detection.utils import ops as utils_ops\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import codecs\n",
    "import io\n",
    "import base64\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_dir):\n",
    "    \n",
    "    model = tf.saved_model.load(str(model_dir))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = r'D:\\(Code)\\Python\\TF2_MASKRCNN_TUTORIAL\\saved_model\\saved_model'\n",
    "masking_model = load_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
    "PATH_TO_TEST_IMAGES_DIR = pathlib.Path(r'D:\\(Code)\\Python\\TF2_MASKRCNN_TUTORIAL\\dataset\\test_images')\n",
    "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeImageForJson(image):\n",
    "    img_pil = Image.fromarray(image, mode='RGB')\n",
    "    f = io.BytesIO()\n",
    "    img_pil.save(f, format='PNG')\n",
    "    data = f.getvalue()\n",
    "    encData = codecs.encode(data, 'base64').decode()\n",
    "    encData = encData.replace('\\n', '')\n",
    "    return encData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_arr_to_b64(img_arr):\n",
    "    img_pil = Image.fromarray(img_arr)\n",
    "    f = io.BytesIO()\n",
    "    img_pil.save(f, format='PNG')\n",
    "    img_bin = f.getvalue()\n",
    "    if hasattr(base64, 'encodebytes'):\n",
    "        img_b64 = base64.encodebytes(img_bin)\n",
    "    else:\n",
    "        img_b64 = base64.encodestring(img_bin)\n",
    "    return img_b64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_and_get_labelme_json(model, image_np, image_path, img_width, img_height):    \n",
    "    print(image_path)\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "        \n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    detections = model(input_tensor)\n",
    "\n",
    "    # Handle models with masks:\n",
    "    if \"detection_masks\" in detections:\n",
    "        # Reframe the the bbox mask to the image size.\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(detections[\"detection_masks\"][0], detections[\"detection_boxes\"][0],image_np.shape[0], image_np.shape[1])      \n",
    "        detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,tf.uint8)\n",
    "        detections[\"detection_masks_reframed\"] = detection_masks_reframed.numpy()\n",
    "\n",
    "    scores = np.asarray(detections[\"detection_scores\"][0])    \n",
    "    mask = np.asarray(detections[\"detection_masks_reframed\"])\n",
    "        \n",
    "\n",
    "    ls = []\n",
    " \n",
    "    ## Each image should be have their own mask and json\n",
    "    for i, img in enumerate(mask):\n",
    "        if(scores[i] > 0.5):        \n",
    "            shape_dictionary = {\"label\" : \"aruco\",\n",
    "                        \"points\" : [],\n",
    "                        \"group_id\" : None,\n",
    "                        \"shape_type\": \"polygon\",\n",
    "                        \"flags\":{}}  \n",
    "                \n",
    "            img_mask = np.empty(shape=(mask.shape[1], mask.shape[2],3),dtype='uint8')\n",
    "            \n",
    "            ret, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY)\n",
    "            countours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)                      \n",
    "            epsilon = 0.1 * cv2.arcLength(countours[0], True)\n",
    "            approx = cv2.approxPolyDP(countours[0], epsilon, True)   \n",
    "            approx_new = np.reshape(approx, (4,2))            \n",
    "            shape_dictionary[\"points\"] = approx_new.tolist()\n",
    "            #cv2.drawContours(img_mask, approx, -1, (0, 255, 0), 3)\n",
    "            #display(Image.fromarray(img_mask))           \n",
    "            ls.append(shape_dictionary) \n",
    "        \n",
    "    dictionary = {\n",
    "        \"version\": \"5.0.1\",\n",
    "        \"flags\": {} ,\n",
    "        \"shapes\": [],\n",
    "        \"imagePath\" : \"\",\n",
    "        \"imageData\": \"\",\n",
    "        \"imageHeight\": \"\",\n",
    "        \"imageWidth\": \"\"\n",
    "    }\n",
    "            \n",
    "    dictionary[\"shapes\"] = ls\n",
    "    dictionary[\"imageData\"] = encodeImageForJson(image_np)   \n",
    "    \n",
    "    dictionary[\"imagePath\"] = image_path\n",
    "    dictionary[\"imageHeight\"] = img_height\n",
    "    dictionary[\"imageWidth\"] = img_width\n",
    "    \n",
    "    with open(f\"{os.path.splitext(image_path)[0]}.json\", \"w\") as outfile:\n",
    "        json.dump(dictionary, outfile, indent=2)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_inference(model, image_path):\n",
    "    \n",
    "    img = Image.open(image_path)\n",
    "    ori_width = img.width\n",
    "    ori_height = img.height\n",
    "    \n",
    "\n",
    "    # Load image\n",
    "    image_np = np.array(img)\n",
    "    \n",
    "    # Actual detection.\n",
    "    img = run_inference_and_get_labelme_json(model, image_np, os.path.basename(str(image_path)), str(ori_width), str(ori_height))\n",
    "\n",
    "    #display(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WIN_20220711_22_37_23_Pro.jpg\n",
      "15.220494747161865\n"
     ]
    }
   ],
   "source": [
    "for image_path in TEST_IMAGE_PATHS:\n",
    "    t1 = time.time()\n",
    "    show_inference(masking_model, image_path)\n",
    "    print(time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1db3d94691cf4e3ff3407b252d5528090bbe89f03b1dc2ffc7d7e0871bf23e02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
